

<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Executive Master Statistique et Big Data: Année 2020-2021 - Université Paris-Dauphine &mdash; My AI website 0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../../../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../../../../_static/nbsphinx-code-cells.css?v=2aa19091" />

  
      <script src="../../../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script data-url_root="../../../../../" id="documentation_options" src="../../../../../_static/documentation_options.js?v=e031e9a9"></script>
      <script src="../../../../../_static/doctools.js?v=888ff710"></script>
      <script src="../../../../../_static/sphinx_highlight.js?v=4825356b"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../../index.html" class="icon icon-home">
            My AI website
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../probabilities/index.html">Probability Theory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../index.html">Statistical Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../machine_learning/index.html">Machine Learning</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../index.html">My AI website</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Executive Master Statistique et Big Data: Année 2020-2021 - Université Paris-Dauphine</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../../../_sources/AI/statistic/modeling/non_linear_models/nonparametric_regression/SNP_DM_DThébault.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="Executive-Master-Statistique-et-Big-Data:-Année-2020-2021---Université-Paris-Dauphine">
<h1>Executive Master Statistique et Big Data: Année 2020-2021 - Université Paris-Dauphine<a class="headerlink" href="#Executive-Master-Statistique-et-Big-Data:-Année-2020-2021---Université-Paris-Dauphine" title="Permalink to this heading"></a></h1>
</section>
<section id="Régression-non-paramétrique">
<h1>Régression non-paramétrique<a class="headerlink" href="#Régression-non-paramétrique" title="Permalink to this heading"></a></h1>
<section id="Cours-enseigné-par-Céline-Duval">
<h2>Cours enseigné par Céline Duval<a class="headerlink" href="#Cours-enseigné-par-Céline-Duval" title="Permalink to this heading"></a></h2>
</section>
<section id="Devoir-Maison-rédigé-par-David-Thébault">
<h2>Devoir Maison rédigé par David Thébault<a class="headerlink" href="#Devoir-Maison-rédigé-par-David-Thébault" title="Permalink to this heading"></a></h2>
</section>
<section id="Cadre">
<h2>Cadre<a class="headerlink" href="#Cadre" title="Permalink to this heading"></a></h2>
<p>On dispose de données $(Xi, Yi)_{1 <span class="math">\leq `i :nbsphinx-math:</span>leq 5000`} $, où les <span class="math notranslate nohighlight">\(X_i\)</span> et les <span class="math notranslate nohighlight">\(Y_i\)</span> sont des réalisations de variables aléatoires réelles admettant la représentation</p>
<p>$ Y_i = r(X_i) + <span class="math">\sigma`(X_i)\*:nbsphinx-math:</span>xi`_i $ avec $ 1 <span class="math">\leq `i :nbsphinx-math:</span>leq 5000` $</p>
<ul class="simple">
<li><p>Les <span class="math notranslate nohighlight">\(\xi_i\)</span> sont indépendantes et identiquement distribuées, avec $E[<span class="math">\xi</span>_1] = 0 $, et <span class="math notranslate nohighlight">\(E[\xi_1^2] = 1\)</span>, et ont une densité <span class="math notranslate nohighlight">\(\mu\)</span>.</p></li>
<li><p>La fonction <span class="math notranslate nohighlight">\(x \mapsto \sigma(x)\)</span> est strictement positive. Si <span class="math notranslate nohighlight">\(\sigma\)</span> est constante on parle d’un modèle homoscédastique, sinon le modèle est dit hétéroscédastique.</p></li>
<li><p>Les <span class="math notranslate nohighlight">\(X_i\)</span> sont indépendantes et identiquement distribuées de densité <span class="math notranslate nohighlight">\(g : [1; 6] \mapsto \mathbb{R}_+\)</span>, et indépendantes des <span class="math notranslate nohighlight">\(\xi_i\)</span>.</p></li>
<li><p>La fonction <span class="math notranslate nohighlight">\(r : \mathbb{R} \mapsto\mathbb{R}\)</span>, vérifie <span class="math notranslate nohighlight">\(|r(x)| \leq 2\)</span> pour tout <span class="math notranslate nohighlight">\(x \in [1; 6]\)</span>.</p></li>
</ul>
<p>On dispose de deux jeux de données, Data1 et Data2, dont la première colonne correspond aux <span class="math notranslate nohighlight">\(X_i\)</span> et la seconde colonne correspond aux <span class="math notranslate nohighlight">\(Y_i\)</span>.</p>
<ul class="simple">
<li><p>Data1: Dans ce jeu de données la variance des erreurs ne dépend pas de <span class="math notranslate nohighlight">\(X\)</span> (modèle homoscédastique).</p></li>
<li><p>Data2 : Les différences avec les donnees Data1 sont la loi <span class="math notranslate nohighlight">\(\mu\)</span> des erreurs <span class="math notranslate nohighlight">\(\xi\)</span> et le fait que <span class="math notranslate nohighlight">\(\sigma\)</span> est non constante (modèle hétéroscédastique).</p></li>
</ul>
<p>On a les mêmes valeurs pour les <span class="math notranslate nohighlight">\(X_i\)</span> et la même fonction de régression r dans Data1 et Data2.</p>
</section>
<section id="Objectifs">
<h2>Objectifs<a class="headerlink" href="#Objectifs" title="Permalink to this heading"></a></h2>
<p>Les objectifs des 3 parties qui suivent sont :</p>
<ol class="arabic simple">
<li><p>Reconstruire <span class="math notranslate nohighlight">\(x \mapsto g(x)\)</span> graphiquement et étudier si <span class="math notranslate nohighlight">\(g\)</span> est la densité uniforme ou non.</p></li>
<li><p>Reconstruire <span class="math notranslate nohighlight">\(x \mapsto r(x)\)</span> graphiquement.</p></li>
<li><p>Explorer les propriétés de <span class="math notranslate nohighlight">\(x \mapsto \mu(x)\)</span> et <span class="math notranslate nohighlight">\(x \mapsto \sigma(x)\)</span>.</p></li>
</ol>
</section>
<section id="1.-Etude-de-la-densité-g-des-X">
<h2>1. Etude de la densité g des X<a class="headerlink" href="#1.-Etude-de-la-densité-g-des-X" title="Permalink to this heading"></a></h2>
<p>Pour cette partie on utilisera la première colonne des données <strong>Data1</strong>.</p>
<p>1.1. Construire un estimateur à noyau <span class="math notranslate nohighlight">\(\hat{g}_{n,h}(x)\)</span> de <span class="math notranslate nohighlight">\(g(x)\)</span> pour une fenêtre de lissage <span class="math notranslate nohighlight">\(h &gt; 0\)</span> donnée et représenter graphiquement <span class="math notranslate nohighlight">\(x \mapsto \hat{g}_{n,h}(x)\)</span> pour différentes valeurs de h que vous choisirez. On discutera la raison pour laquelle ce choix est important.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[138]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># import des librairies</span>

<span class="kn">from</span> <span class="nn">IPython.core.interactiveshell</span> <span class="kn">import</span> <span class="n">InteractiveShell</span>
<span class="n">InteractiveShell</span><span class="o">.</span><span class="n">ast_node_interactivity</span> <span class="o">=</span> <span class="s2">&quot;all&quot;</span>

<span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="o">*</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span> <span class="c1"># gestion de données de type DataFrame</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span> <span class="c1"># gestion des tableaux et opérations d&#39;algèbre linéaire de base</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span> <span class="c1"># graphes</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span> <span class="c1"># statistics et visualisation</span>
<span class="kn">import</span> <span class="nn">os.path</span> <span class="c1"># gestion des path</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">st</span> <span class="c1"># librairie de calcul scientifique basée sur numpy, import du package statistiques</span>

<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">expon</span>

<span class="c1"># Deux fonctions (au moins) permettent de faire de l&#39;estimation à noyau sous Python</span>
<span class="c1"># La première KDEUnivarite</span>
<span class="kn">from</span> <span class="nn">statsmodels.nonparametric.kde</span> <span class="kn">import</span> <span class="n">KDEUnivariate</span>
<span class="kn">from</span> <span class="nn">statsmodels.nonparametric.kernel_regression</span> <span class="kn">import</span> <span class="n">KernelReg</span> <span class="c1"># NW et Polynome locaux p=0</span>
<span class="kn">import</span> <span class="nn">statsmodels.nonparametric.bandwidths</span>
<span class="c1"># La seconde KernelDensity</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KernelDensity</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="c1">#from sklearn_extensions.kernel_regression import KernelRegression</span>
<br/></pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[139]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Nous allons commencer par charger les données Data1.csv et Data2.csv</span>

<span class="n">path_work_win</span> <span class="o">=</span> <span class="sa">r</span><span class="s1">&#39;/Users/davidtbo/OneDrive/Documents/Data_Science/10_Régression_non_paramétrique&#39;</span>
<span class="n">path_win_Data1</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path_work_win</span><span class="p">,</span> <span class="s1">&#39;Data1.csv&#39;</span><span class="p">)</span>
<span class="n">path_win_Data2</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path_work_win</span><span class="p">,</span> <span class="s1">&#39;Data2.csv&#39;</span><span class="p">)</span>

<span class="n">path_win_Data1</span> <span class="o">=</span> <span class="n">path_win_Data1</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">&quot;</span><span class="p">,</span><span class="s2">&quot;/&quot;</span><span class="p">)</span>
<span class="n">path_win_Data1</span> <span class="o">=</span> <span class="n">path_win_Data1</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">&quot;</span><span class="p">,</span><span class="s2">&quot;/&quot;</span><span class="p">)</span>

<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">path_win_Data1</span><span class="p">):</span>

    <span class="n">Data1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path_win_Data1</span><span class="p">)</span>

<span class="k">else</span><span class="p">:</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;absence du fichier: &quot;</span><span class="p">,</span><span class="n">path_win_Data1</span><span class="p">)</span>

<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">path_win_Data2</span><span class="p">):</span>

    <span class="n">Data2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path_win_Data2</span><span class="p">)</span>

<span class="k">else</span><span class="p">:</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;absence du fichier: &quot;</span><span class="p">,</span><span class="n">path_win_Data2</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[140]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Data1</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">Data2</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[140]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>X</th>
      <th>Y1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1.034366</td>
      <td>1.035967</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>3.643734</td>
      <td>1.368706</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>5.701457</td>
      <td>1.030205</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>5.420473</td>
      <td>1.309923</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>1.009888</td>
      <td>1.065813</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[140]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>X</th>
      <th>Y2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1.034366</td>
      <td>0.458698</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>3.643734</td>
      <td>1.439542</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>5.701457</td>
      <td>0.907269</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>5.420473</td>
      <td>1.807085</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>1.009888</td>
      <td>1.393327</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[141]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">type</span><span class="p">(</span><span class="n">Data1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[141]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
pandas.core.frame.DataFrame
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[142]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Data1</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[142]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(5000, 3)
</pre></div></div>
</div>
<p>Résumé statistique des <span class="math notranslate nohighlight">\(X_i\)</span>, <span class="math notranslate nohighlight">\(Y_i\)</span> des deux jeux de données Data1 et Data2</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[143]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Data1</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
<span class="n">Data2</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[143]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>X</th>
      <th>Y1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>5000.000000</td>
      <td>5000.000000</td>
      <td>5000.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>2500.500000</td>
      <td>3.527486</td>
      <td>1.235370</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1443.520003</td>
      <td>1.839532</td>
      <td>0.585506</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>-4.952235</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>1250.750000</td>
      <td>1.617688</td>
      <td>0.833701</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>2500.500000</td>
      <td>3.576746</td>
      <td>1.175970</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>3750.250000</td>
      <td>5.418334</td>
      <td>1.536368</td>
    </tr>
    <tr>
      <th>max</th>
      <td>5000.000000</td>
      <td>6.000000</td>
      <td>10.325009</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[143]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>X</th>
      <th>Y2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>5000.000000</td>
      <td>5000.000000</td>
      <td>5000.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>2500.500000</td>
      <td>3.527486</td>
      <td>1.226723</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1443.520003</td>
      <td>1.839532</td>
      <td>2.075400</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>-7.603334</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>1250.750000</td>
      <td>1.617688</td>
      <td>0.233537</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>2500.500000</td>
      <td>3.576746</td>
      <td>1.046899</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>3750.250000</td>
      <td>5.418334</td>
      <td>2.250319</td>
    </tr>
    <tr>
      <th>max</th>
      <td>5000.000000</td>
      <td>6.000000</td>
      <td>10.562283</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>Représentons graphiquemenent, par un histogramme, la variable X.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[144]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Data1</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span> <span class="o">=</span> <span class="s2">&quot;hist&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[144]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;AxesSubplot:ylabel=&#39;Frequency&#39;&gt;
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../../../_images/AI_statistic_modeling_non_linear_models_nonparametric_regression_SNP_DM_DTh%C3%A9bault_13_1.png" src="../../../../../_images/AI_statistic_modeling_non_linear_models_nonparametric_regression_SNP_DM_DTh%C3%A9bault_13_1.png" />
</div>
</div>
<p>La distribution de <span class="math notranslate nohighlight">\(X\)</span> est bimodale. La variable <span class="math notranslate nohighlight">\(X\)</span> ne suit pas la loi normale.</p>
</section>
</section>
<section id="id1">
<h1>1. Etude de la densité g des X<a class="headerlink" href="#id1" title="Permalink to this heading"></a></h1>
<p><em>Pour cette partie on utilisera la première colonne des données</em> <strong>Data1</strong>.</p>
<section id="1.1.-Estimateur-à-noyau-\hat{g}_{n,h}(x)-de-la-densité-g(x)">
<h2>1.1. Estimateur à noyau <span class="math notranslate nohighlight">\(\hat{g}_{n,h}(x)\)</span> de la densité <span class="math notranslate nohighlight">\(g(x)\)</span><a class="headerlink" href="#1.1.-Estimateur-à-noyau-\hat{g}_{n,h}(x)-de-la-densité-g(x)" title="Permalink to this heading"></a></h2>
<p>Construire un estimateur à noyau <span class="math notranslate nohighlight">\(\hat{g}_{n,h}(x)\)</span> de <span class="math notranslate nohighlight">\(g(x)\)</span> pour une fenêtre de lissage <span class="math notranslate nohighlight">\(h &gt; 0\)</span> donnée et représenter graphiquement <span class="math notranslate nohighlight">\(x \mapsto \hat{g}_{n,h}(x)\)</span> pour différentes valeurs de h que vous choisirez. On discutera la raison pour laquelle ce choix est important.</p>
<p>Pour construire un estimateur à noyau <span class="math notranslate nohighlight">\(\hat{g}_{n,h}(x)\)</span> de <span class="math notranslate nohighlight">\(g(x)\)</span> pour une fenêtre de lissage <span class="math notranslate nohighlight">\(h &gt; 0\)</span> donnée, nous reprenons la fonction vue en cours qui utilise la méthode KDEUnivariate.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[145]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">g_hat</span><span class="p">(</span><span class="n">grid</span> <span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Univariate Kernel Density Estimation with Statsmodels&quot;&quot;&quot;</span>
    <span class="c1"># grid: grille de points où l&#39;estimateur de $g$ sera évalué</span>
    <span class="c1"># X: échantillon (X_1,..., X_n)</span>
    <span class="c1"># h: choix de la taille de la fenêtre</span>
    <span class="c1"># **kwargs: arguments optionels Par défaut le noyau gaussien est utilisé</span>
    <span class="n">kde</span> <span class="o">=</span> <span class="n">KDEUnivariate</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">kde</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">bw</span> <span class="o">=</span> <span class="n">h</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">kde</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">grid</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Ci-dessous nous représentons graphiquement la fonction <span class="math notranslate nohighlight">\(x \mapsto \hat{g}_{n,h}(x)\)</span> pour différentes valeurs du paramètre de lissage h que nous avons déterminées.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[146]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">500</span><span class="p">)</span>
<span class="n">g1</span><span class="p">,</span>  <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">g_hat</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">Data1</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">],</span><span class="n">h</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>
<span class="n">g3</span><span class="p">,</span>  <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">g_hat</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">Data1</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">],</span><span class="n">h</span><span class="o">=</span><span class="mf">0.3</span><span class="p">))</span>
<span class="n">g5</span><span class="p">,</span>  <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">g_hat</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">Data1</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">],</span><span class="n">h</span><span class="o">=</span><span class="mf">0.5</span><span class="p">))</span>
<span class="n">g7</span><span class="p">,</span>  <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">g_hat</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">Data1</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">],</span><span class="n">h</span><span class="o">=</span><span class="mf">0.7</span><span class="p">))</span>
<span class="n">g9</span><span class="p">,</span>  <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">g_hat</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">Data1</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">],</span><span class="n">h</span><span class="o">=</span><span class="mf">0.9</span><span class="p">))</span>
<span class="n">g11</span><span class="p">,</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">g_hat</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">Data1</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">],</span><span class="n">h</span><span class="o">=</span><span class="mf">1.1</span><span class="p">))</span>
<span class="n">g13</span><span class="p">,</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">g_hat</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">Data1</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">],</span><span class="n">h</span><span class="o">=</span><span class="mf">1.3</span><span class="p">))</span>
<span class="n">g15</span><span class="p">,</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">g_hat</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">Data1</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">],</span><span class="n">h</span><span class="o">=</span><span class="mf">1.5</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="n">g1</span><span class="p">,</span> <span class="n">g3</span><span class="p">,</span> <span class="n">g5</span><span class="p">,</span> <span class="n">g7</span><span class="p">,</span> <span class="n">g9</span><span class="p">,</span> <span class="n">g11</span><span class="p">,</span> <span class="n">g13</span><span class="p">,</span> <span class="n">g15</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;h = 0,1&#39;</span><span class="p">,</span> <span class="s1">&#39;h = 0,3&#39;</span><span class="p">,</span> <span class="s1">&#39;h = 0,7&#39;</span><span class="p">,</span> <span class="s1">&#39;h = 0,9&#39;</span><span class="p">,</span> <span class="s1">&#39;h = 1,1&#39;</span><span class="p">,</span> <span class="s1">&#39;h = 1,3&#39;</span><span class="p">,</span> <span class="s1">&#39;h = 1,5&#39;</span><span class="p">],</span>
              <span class="n">loc</span> <span class="o">=</span> <span class="s1">&#39;upper right&#39;</span> <span class="p">,</span> <span class="n">title</span> <span class="o">=</span> <span class="s1">&#39;Légende&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;fonction densité&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Représentation de la densité&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[146]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;matplotlib.legend.Legend at 0x7ff589437b80&gt;
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[146]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Text(0.5, 0, &#39;X&#39;)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[146]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Text(0, 0.5, &#39;fonction densité&#39;)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[146]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Text(0.5, 1.0, &#39;Représentation de la densité&#39;)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../../../_images/AI_statistic_modeling_non_linear_models_nonparametric_regression_SNP_DM_DTh%C3%A9bault_20_4.png" src="../../../../../_images/AI_statistic_modeling_non_linear_models_nonparametric_regression_SNP_DM_DTh%C3%A9bault_20_4.png" />
</div>
</div>
<ul class="simple">
<li><p>Pour les valeurs de h, <span class="math notranslate nohighlight">\(h \in ]0; 1.5]\)</span>.</p>
<ul>
<li><p>La densité est bimodale,</p></li>
<li><p>Plus h est grand, plus les deux bosses deviennent plates</p></li>
<li><p>Pour <span class="math notranslate nohighlight">\(h = 0.1\)</span> on observe une plus grande volatilité autour de la moyenne.</p></li>
</ul>
</li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[147]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">500</span><span class="p">)</span>
<span class="n">g17</span><span class="p">,</span>  <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">g_hat</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">Data1</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">],</span><span class="n">h</span><span class="o">=</span><span class="mf">1.7</span><span class="p">))</span>
<span class="n">g19</span><span class="p">,</span>  <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">g_hat</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">Data1</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">],</span><span class="n">h</span><span class="o">=</span><span class="mf">1.9</span><span class="p">))</span>
<span class="n">g100</span><span class="p">,</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">g_hat</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">Data1</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">],</span><span class="n">h</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="n">g17</span><span class="p">,</span> <span class="n">g19</span><span class="p">,</span> <span class="n">g100</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;h = 1,7&#39;</span><span class="p">,</span> <span class="s1">&#39;h = 1,9&#39;</span><span class="p">,</span> <span class="s1">&#39;h = 10&#39;</span><span class="p">],</span>
              <span class="n">loc</span> <span class="o">=</span> <span class="s1">&#39;upper right&#39;</span> <span class="p">,</span> <span class="n">title</span> <span class="o">=</span> <span class="s1">&#39;Légende&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;fonction densité&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Représentation de la densité&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[147]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;matplotlib.legend.Legend at 0x7ff5aa276520&gt;
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[147]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Text(0.5, 0, &#39;X&#39;)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[147]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Text(0, 0.5, &#39;fonction densité&#39;)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[147]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Text(0.5, 1.0, &#39;Représentation de la densité&#39;)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../../../_images/AI_statistic_modeling_non_linear_models_nonparametric_regression_SNP_DM_DTh%C3%A9bault_22_4.png" src="../../../../../_images/AI_statistic_modeling_non_linear_models_nonparametric_regression_SNP_DM_DTh%C3%A9bault_22_4.png" />
</div>
</div>
<ul class="simple">
<li><p>Pour <span class="math notranslate nohighlight">\(h &gt; 1,5\)</span> :</p>
<ul>
<li><p>la densité est unimodale</p></li>
<li><p>la variable est centrée,</p></li>
<li><p>Pour <span class="math notranslate nohighlight">\(h = 10\)</span>, la densité devient quasiment plate.</p></li>
</ul>
</li>
</ul>
<p>Le choix de h est primordial car si cet hyperparamètre est trop grand, le lissage ne permettra pas de reproduire la forme bimodale observée grâce à l’histogramme. Si h est trop petit, on observe une relativement forte volatilité de la densité autour de la moyenne, la variance est plus grande. Ce que l’on gagne en précision avec h petit (biais plus petit sous condition de régularité de g), impacte négativement la variance qui augmente. Le choix de h est un compromis biais-variance - biais
contrôlé et une variance petite - comme souvent en statistiques.</p>
<p>D’une part les caractéristiques des données semblent être mieux représentées quand <span class="math notranslate nohighlight">\(h \leq 1.5\)</span> et d’autre part avec les effets observés précédemment sur la variance d’un h trop petit, on aurait tendance à privilégier <span class="math notranslate nohighlight">\(h \geq 0.1\)</span>.</p>
</section>
<section id="1.2.-Représentation-graphique-de-l'estimateur-\hat{g}_{n,h}(x)-de-la-densité-g(x)">
<h2>1.2. Représentation graphique de l’estimateur <span class="math notranslate nohighlight">\(\hat{g}_{n,h}(x)\)</span> de la densité <span class="math notranslate nohighlight">\(g(x)\)</span><a class="headerlink" href="#1.2.-Représentation-graphique-de-l'estimateur-\hat{g}_{n,h}(x)-de-la-densité-g(x)" title="Permalink to this heading"></a></h2>
<ul class="simple">
<li><p>Nous avons besoin de déterminer l’estimateur de la fenêtre h noté $ <span class="math">\hat{h}</span>_n $</p></li>
</ul>
<ul class="simple">
<li><p>La règle du pouce de Silverman et celle de Scott nous fournissent une première approximation de h pour les fonctions de densité deux fois dérivable. L’hyperparamètre h1 de Scott se retrouve par la formule suivante: <span class="math notranslate nohighlight">\(h_{est} = 1.06*\sigma(X)*n^{\frac{-1}{2\alpha + 1}}\)</span> avec ici <span class="math notranslate nohighlight">\(\alpha = 2\)</span> pour g deux fois dérivable.</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[148]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span><span class="o">=</span> <span class="mi">5000</span>
<span class="n">h1</span> <span class="o">=</span> <span class="n">statsmodels</span><span class="o">.</span><span class="n">nonparametric</span><span class="o">.</span><span class="n">bandwidths</span><span class="o">.</span><span class="n">bw_scott</span><span class="p">(</span><span class="n">Data1</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">])</span>
<span class="n">h2</span> <span class="o">=</span> <span class="n">statsmodels</span><span class="o">.</span><span class="n">nonparametric</span><span class="o">.</span><span class="n">bandwidths</span><span class="o">.</span><span class="n">bw_silverman</span><span class="p">(</span><span class="n">Data1</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">])</span>
<span class="p">(</span><span class="mf">1.06</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">Data1</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">]))</span><span class="o">*</span><span class="n">n</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="mi">5</span><span class="p">),</span> <span class="n">h1</span><span class="p">,</span> <span class="n">h2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[148]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(0.35495697624782646, 0.3546575787072305, 0.3014087071166265)
</pre></div></div>
</div>
<p>Les estimateurs h1 et h2 (Scott et Silverman) de l’hyperparamètre h sont calculés en faisant l’hypothèse que la densité g des <span class="math notranslate nohighlight">\(X_i\)</span> est deux fois dérivable, mais la fonction de densité peut être dérivable plus de deux fois. A contratrio, si par exemple la densité n’était qu’une fois dérivable, l’estimateur de Scott serait égal à:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[149]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span><span class="o">=</span><span class="mi">5000</span>
<span class="mf">1.06</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">Data1</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">]))</span><span class="o">*</span><span class="n">n</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[149]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0.11401965315212556
</pre></div></div>
</div>
<p>Estimation de h par validation croisée (leave one out)</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[150]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bandwidths</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span> <span class="c1"># nous fixons une grille de 30 points compris entre 0 et 1 sur laquelle évaluerons</span>
<span class="n">bandwidths</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[150]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([0.        , 0.03448276, 0.06896552, 0.10344828, 0.13793103,
       0.17241379, 0.20689655, 0.24137931, 0.27586207, 0.31034483,
       0.34482759, 0.37931034, 0.4137931 , 0.44827586, 0.48275862,
       0.51724138, 0.55172414, 0.5862069 , 0.62068966, 0.65517241,
       0.68965517, 0.72413793, 0.75862069, 0.79310345, 0.82758621,
       0.86206897, 0.89655172, 0.93103448, 0.96551724, 1.        ])
</pre></div></div>
</div>
<p>Nous devons procéder à un reformatage des données X pour utiliser les fonctions d optimisation ci-après.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[151]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">Data1</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">]</span>
<span class="n">Xnew</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">Xnew</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[151]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(5000, 1)
</pre></div></div>
</div>
<p>Nous utilisons la fonction GrideSearchCV pour déterminer l’estimateur optimal de l’hyperparamètre h.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[152]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">GG</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">KernelDensity</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;gaussian&#39;</span><span class="p">),{</span><span class="s1">&#39;bandwidth&#39;</span><span class="p">:</span> <span class="n">bandwidths</span><span class="p">},</span><span class="n">cv</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">GG</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xnew</span><span class="p">)</span>
<span class="n">h_cv</span> <span class="o">=</span> <span class="n">GG</span><span class="o">.</span><span class="n">best_params_</span><span class="p">[</span><span class="s2">&quot;bandwidth&quot;</span><span class="p">]</span>
<span class="n">h_cv</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[152]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
GridSearchCV(cv=2, estimator=KernelDensity(),
             param_grid={&#39;bandwidth&#39;: array([0.        , 0.03448276, 0.06896552, 0.10344828, 0.13793103,
       0.17241379, 0.20689655, 0.24137931, 0.27586207, 0.31034483,
       0.34482759, 0.37931034, 0.4137931 , 0.44827586, 0.48275862,
       0.51724138, 0.55172414, 0.5862069 , 0.62068966, 0.65517241,
       0.68965517, 0.72413793, 0.75862069, 0.79310345, 0.82758621,
       0.86206897, 0.89655172, 0.93103448, 0.96551724, 1.        ])})
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[152]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0.034482758620689655
</pre></div></div>
</div>
<p>L’estimateur h_cv de l’hyperparamètre h calculé par la validation croisée est très petit. Comme nous l’avons vu plus haut, l’estimateur à noyeau de la densité g de X pour un h trop petit <span class="math notranslate nohighlight">\((h &lt; 0.3)\)</span> entraîne une variance plus élevée autour de la moyenne. Pour éviter cela nous préférons comme estimateur de h, l’estimateur <span class="math notranslate nohighlight">\(\hat{h}_n\)</span> de Silverman <span class="math notranslate nohighlight">\(h_2 = 0.30\)</span>.</p>
<p>Nous reprenons à nouveau la fonction vue en cours pour déterminer graphiquement <span class="math notranslate nohighlight">\(\hat{g}_{n,\hat{h}_n}\)</span> selon les trois hyperparamètres Scott, Silverman et celui obtenu par validation croisée.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[153]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Utilisation en densité</span>
<span class="k">def</span> <span class="nf">g_hat</span><span class="p">(</span><span class="n">grid</span> <span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Univariate Kernel Density Estimation with Statsmodels&quot;&quot;&quot;</span>
    <span class="c1"># grid: grille de points où l&#39;estimateur de $f$ sera évalué</span>
    <span class="c1"># X: échantillon (X_1,..., X_n)</span>
    <span class="c1"># h: choix de la taille de la fenêtre</span>
    <span class="c1"># **kwargs: arguments optionels Par défaut le noyau gaussien est utilisé</span>
    <span class="n">kde</span> <span class="o">=</span> <span class="n">KDEUnivariate</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">kde</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">bw</span> <span class="o">=</span> <span class="n">h</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">kde</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">grid</span><span class="p">)</span>


<span class="n">g1</span><span class="p">,</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">g_hat</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">h1</span><span class="p">))</span>
<span class="n">g2</span><span class="p">,</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">g_hat</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">h2</span><span class="p">))</span>
<span class="n">g3</span><span class="p">,</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">g_hat</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">h_cv</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="n">g1</span><span class="p">,</span> <span class="n">g2</span><span class="p">,</span> <span class="n">g3</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;h = Scott&#39;</span><span class="p">,</span> <span class="s1">&#39;h = Silverman&#39;</span><span class="p">,</span> <span class="s1">&#39;h = CV&#39;</span><span class="p">],</span><span class="n">loc</span> <span class="o">=</span> <span class="s1">&#39;upper right&#39;</span> <span class="p">,</span> <span class="n">title</span> <span class="o">=</span> <span class="s1">&#39;Légende&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;fonction densité&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Représentation de l estimateur de la densité&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[153]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;matplotlib.legend.Legend at 0x7ff5893c1760&gt;
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[153]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Text(0.5, 0, &#39;X&#39;)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[153]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Text(0, 0.5, &#39;fonction densité&#39;)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[153]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Text(0.5, 1.0, &#39;Représentation de l estimateur de la densité&#39;)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../../../_images/AI_statistic_modeling_non_linear_models_nonparametric_regression_SNP_DM_DTh%C3%A9bault_39_4.png" src="../../../../../_images/AI_statistic_modeling_non_linear_models_nonparametric_regression_SNP_DM_DTh%C3%A9bault_39_4.png" />
</div>
</div>
<p>La variance est beaucoup plus élevée quand on utilise l’estimateur de l’hyperparamètre h obtenu par validation croisée dont la valeur est relativement faible.</p>
<p>Fonction de répartition de la loi uniforme <span class="math notranslate nohighlight">\(U[a;b]\)</span></p>
</section>
<section id="1.3.-Implémenter-un-QQ-plot-pour-vérifier-l'hypothèse-g-est-la-distribution-uniforme">
<h2>1.3. Implémenter un QQ-plot pour vérifier l’hypothèse <em>g</em> est la distribution uniforme<a class="headerlink" href="#1.3.-Implémenter-un-QQ-plot-pour-vérifier-l'hypothèse-g-est-la-distribution-uniforme" title="Permalink to this heading"></a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[154]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">unif</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">)</span>
<span class="n">st</span><span class="o">.</span><span class="n">probplot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">dist</span><span class="o">=</span><span class="n">unif</span><span class="p">,</span> <span class="n">plot</span><span class="o">=</span><span class="n">plt</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[154]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
((array([1.00083172, 1.00201885, 1.00321877, ..., 6.99678123, 6.99798115,
         6.99916828]),
  array([1.        , 1.00000241, 1.00000245, ..., 5.99999668, 5.99999799,
         5.99999985])),
 (1.048060171500124, -0.6647543013787347, 0.9868503047727718))
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../../../_images/AI_statistic_modeling_non_linear_models_nonparametric_regression_SNP_DM_DTh%C3%A9bault_43_1.png" src="../../../../../_images/AI_statistic_modeling_non_linear_models_nonparametric_regression_SNP_DM_DTh%C3%A9bault_43_1.png" />
</div>
</div>
<p>L’hypothèse que g soit la distribution uniforme me paraît peu probable car la forme de la courbe bleue des quantiles associés aux observations n’est pas alignée avec les quantiles de la loi uniforme. La courbe bleue est trop sinusoïdale et s’éloigne régulièrement de la première bissectrice.</p>
</section>
<section id="1.4.-Zone-de-l'espace-où-l'estimation-de-r-sera-plus-précise">
<h2>1.4. Zone de l’espace où l’estimation de r sera plus précise<a class="headerlink" href="#1.4.-Zone-de-l'espace-où-l'estimation-de-r-sera-plus-précise" title="Permalink to this heading"></a></h2>
<p>L’estimation de r sera la plus précise là où les observations des <span class="math notranslate nohighlight">\(X_i\)</span> seront les plus nombreux i.e. au voisinage de <span class="math notranslate nohighlight">\(1^+\)</span> et <span class="math notranslate nohighlight">\(6^-\)</span> et nous avons vu qu’à ces voisinages l’estimation de g était fortement dépendante du choix de h.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[155]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Data1</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span> <span class="o">=</span> <span class="s2">&quot;hist&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;bins&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[155]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;AxesSubplot:ylabel=&#39;Frequency&#39;&gt;
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[155]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Text(0.5, 0, &#39;bins&#39;)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../../../_images/AI_statistic_modeling_non_linear_models_nonparametric_regression_SNP_DM_DTh%C3%A9bault_47_2.png" src="../../../../../_images/AI_statistic_modeling_non_linear_models_nonparametric_regression_SNP_DM_DTh%C3%A9bault_47_2.png" />
</div>
</div>
</section>
<section id="1.5.-Estimateur-$-\hat{c}_n^{(k)}$-de-c(k).">
<h2>1.5. Estimateur $ <span class="math">\hat{c}</span>_n^{(k)}$ de <span class="math notranslate nohighlight">\(c(k)\)</span>.<a class="headerlink" href="#1.5.-Estimateur-$-\hat{c}_n^{(k)}$-de-c(k)." title="Permalink to this heading"></a></h2>
<p>Pour $ k <span class="math">\geq 1</span> $, on pose $ c(k) = <span class="math">\int</span>_1<sup>6{x</sup>kg(x)dx} $.</p>
<p>Construire un estimateur $ <span class="math">\hat{c}</span>_n^{(k)}$ de <span class="math notranslate nohighlight">\(c(k)\)</span>. On pourra en particulier discuter de la qualité de l’estimation en prenant <span class="math notranslate nohighlight">\(k=0\)</span>.</p>
<p>Si la densité <span class="math notranslate nohighlight">\(g(x)\)</span> de <span class="math notranslate nohighlight">\(X\)</span> est la distribution uniforme <span class="math notranslate nohighlight">\(\textit{U}[1,6]\)</span> alors <span class="math notranslate nohighlight">\(c(k) = \mathbb{E}[X^k\mathbb{1}_{[1,6]}(X)]\)</span>. Par la méthode de Monte-Carlo on obtient l’estimateur de <span class="math notranslate nohighlight">\(c(k)\)</span> suivant:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[156]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span><span class="o">=</span><span class="mi">5000</span>
<span class="n">zgrid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">5000</span><span class="p">)</span>
<span class="n">u</span><span class="o">=</span><span class="n">st</span><span class="o">.</span><span class="n">uniform</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">u</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
<span class="n">X</span><span class="o">=</span><span class="n">Data1</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;k = &quot;</span><span class="p">,</span><span class="n">k</span><span class="p">)</span>
        <span class="c1">#np.mean(u**k*(u&gt;=1)*(u&lt;=6)) # estimateur Monte-Carlo avec hypothèse de loi uniforme</span>
        <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">u</span><span class="o">**</span><span class="n">k</span><span class="p">)</span> <span class="c1"># estimateur Monte-Carlo avec hypothèse de loi uniforme</span>
        <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">zgrid</span><span class="o">**</span><span class="n">k</span><span class="o">*</span><span class="n">g_hat</span><span class="p">(</span><span class="n">zgrid</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">h2</span><span class="p">))</span> <span class="c1"># estimateur non-paramétrique (h = h2)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[156]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(1.0015348567332862, 6.999558466958535)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
k =  0
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[156]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
1.0
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[156]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0.17090078695149413
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
k =  1
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[156]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
3.9991178705221677
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[156]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0.601977270023502
</pre></div></div>
</div>
<p>Pour k = 0, l’estimateur de Monte-Carlo est bien égal à 1 comme intégrale d’une densité sur R alors que l’estimateur non paramétrique est très inférieur à 1. X ne semble donc pas suivre une loi uniforme sur [1,6].</p>
<p>Les deux estimateurs retournent des valeurs éloignées. La densité de X ne semble donc pas être la loi uniformeloi uniforme ne semble.</p>
</section>
</section>
<section id="2.-Reconstruction-de-r(x)">
<h1>2. Reconstruction de <span class="math notranslate nohighlight">\(r(x)\)</span><a class="headerlink" href="#2.-Reconstruction-de-r(x)" title="Permalink to this heading"></a></h1>
<p><em>Pour cette partie on utilise les données Data1</em></p>
<p>La représentation des données peut donc s’écrire sous la forme du modèle additif suivant:</p>
<p>$ Y_i = r(X_i) + <span class="math">\sigma</span><span class="math">\xi</span>_i $ avec $:nbsphinx-math:<cite>sigma `$ constante (modèle homoscédastique) et :math:`r</cite> la fonction de régression.</p>
<section id="2.1.-Est-il-plausible-de-penser-que-r-soit-linéaire-?">
<h2>2.1. Est-il plausible de penser que <span class="math notranslate nohighlight">\(r\)</span> soit linéaire ?<a class="headerlink" href="#2.1.-Est-il-plausible-de-penser-que-r-soit-linéaire-?" title="Permalink to this heading"></a></h2>
<p>Pour répondre à cette question, nous allons commencer par représenter graphiquement les couples $(X_i,Y_i) $ avec $ 1 <span class="math">\leq `i :nbsphinx-math:</span>leq 5000` .$</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[157]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Data1</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">],</span><span class="n">Data1</span><span class="p">[</span><span class="s1">&#39;Y1&#39;</span><span class="p">],</span> <span class="s1">&#39;r.&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[157]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&lt;matplotlib.lines.Line2D at 0x7ff598720760&gt;]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[157]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(0.0, 3.0)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../../../_images/AI_statistic_modeling_non_linear_models_nonparametric_regression_SNP_DM_DTh%C3%A9bault_59_2.png" src="../../../../../_images/AI_statistic_modeling_non_linear_models_nonparametric_regression_SNP_DM_DTh%C3%A9bault_59_2.png" />
</div>
</div>
<p>Le graphe Y contre X indique qu’il est peu probable que r soit linéaire car il serait difficile de trouver une droite s’ajustant au nuage de points.</p>
<p>Nous allons confirmer cette cette première conclusion par la régression linéaire des Moindres Carrés Ordinaires (paramétrique). Cela nous permet d’utiliser la régression linéaire avec Python. Si r est linéaire, r(x) s’écrit comme $ r(x) = ax + b $ avec <span class="math notranslate nohighlight">\(a, b \in \mathbb{R}\)</span></p>
<p><span class="math notranslate nohighlight">\(\mathbb{E}(Y_i) = a\mathbb{E}(X_i)\)</span> + b</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[158]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[159]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lm</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>Avant d’appliquer la régression linéaire il faut “reshaper” Y1.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[160]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Y</span> <span class="o">=</span> <span class="n">Data1</span><span class="p">[</span><span class="s1">&#39;Y1&#39;</span><span class="p">]</span>
<span class="n">Ynew</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[161]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xnew</span><span class="p">,</span><span class="n">Ynew</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[161]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
LinearRegression()
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[162]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lm</span><span class="o">.</span><span class="n">coef_</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[162]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([[-0.14226115]])
</pre></div></div>
</div>
<p>La pente du modèle de régression linéaire est proche de 0. L’hypothèse “r est linéaire” est peu plausible.</p>
</section>
<section id="2.2.-Construction-de-l'estimateur-non-paramétrique-\widehat{r}_{n,h}(x)-de-r(x)">
<h2>2.2. Construction de l’estimateur non-paramétrique <span class="math notranslate nohighlight">\(\widehat{r}_{n,h}(x)\)</span> de <span class="math notranslate nohighlight">\(r(x)\)</span><a class="headerlink" href="#2.2.-Construction-de-l'estimateur-non-paramétrique-\widehat{r}_{n,h}(x)-de-r(x)" title="Permalink to this heading"></a></h2>
<p>Construire une estimateur non-paramétrique <span class="math notranslate nohighlight">\(\widehat{r}_{n,h}(x)\)</span> de <span class="math notranslate nohighlight">\(r(x)\)</span> pour une fenêtre de lissage $h &gt; 0 $ bien choisie et le représenter graphiquement.</p>
<p>Le choix de h s’effectuera par validation croisée avec l’estimateur de régression de Nadaraya-Watson.</p>
<p>Le principe de la validation croisée consiste à partir de l’échantillon <span class="math notranslate nohighlight">\((X_k,Y_k)_{k\in(1..n),k\neq i}\)</span> privé d’un individu noté i, d’estimer <span class="math notranslate nohighlight">\(\widehat{R}_{(-i),n,h}(x)\)</span> avec h fixé pris dans la grille. A partir de cette estimation, l’erreur moyenne $ err_h = <span class="math">\frac{1}{n}</span><span class="math">\sum</span><span class="math">\limits</span><em>{i=1}^{i=n}({Y_i - :nbsphinx-math:`widehat{R}`</em>{(-i),n,h}(X_i))}^2$ est calculée. On choisit h* comme le h de la grille minimisant cette erreur
moyenne: $ h^* = :nbsphinx-math:<a href="#id2"><span class="problematic" id="id3">`</span></a>underset{h in grid}{argmin}`(err_h) $</p>
<p>Nous allons estimer h par la méthode de régression à noyau Nadaraya-Watson (noté h_cv_nw) et par celle des polynômes locaux (noté h_cv_pl).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[163]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">Data1</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">]</span>
<span class="n">Y1</span> <span class="o">=</span> <span class="n">Data1</span><span class="p">[</span><span class="s1">&#39;Y1&#39;</span><span class="p">]</span>
<span class="n">Kreg_pl</span> <span class="o">=</span> <span class="n">KernelReg</span><span class="p">(</span><span class="n">Y1</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">var_type</span> <span class="o">=</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="n">reg_type</span> <span class="o">=</span> <span class="s1">&#39;ll&#39;</span><span class="p">,</span> <span class="n">bw</span> <span class="o">=</span> <span class="s1">&#39;cv_ls&#39;</span><span class="p">)</span>
<span class="n">h_cv_pl</span> <span class="o">=</span> <span class="n">Kreg_pl</span><span class="o">.</span><span class="n">bw</span>
<span class="n">Kreg_nw</span> <span class="o">=</span> <span class="n">KernelReg</span><span class="p">(</span><span class="n">Y1</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">var_type</span> <span class="o">=</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="n">reg_type</span> <span class="o">=</span> <span class="s1">&#39;lc&#39;</span><span class="p">,</span> <span class="n">bw</span> <span class="o">=</span> <span class="s1">&#39;cv_ls&#39;</span><span class="p">)</span>
<span class="n">h_cv_nw</span> <span class="o">=</span> <span class="n">Kreg_nw</span><span class="o">.</span><span class="n">bw</span>
<span class="n">h_cv_pl</span><span class="p">,</span> <span class="n">h_cv_nw</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[163]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(array([0.15252058]), array([0.08464892]))
</pre></div></div>
</div>
<p>Maintenant que h a été estimé nous pouvons déterminer un estimateur de la fonction de régression <span class="math notranslate nohighlight">\(\widehat{r}_{(\alpha,\beta)(x)}\)</span>. Nous effectuons deux régressions. Une régression avec l’estimateur de lissage obtenu par Nadaraya-Watson et l’autre régression avec l’estimateur obtenu par polynômes locaux.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[164]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Kreg1</span> <span class="o">=</span> <span class="n">KernelReg</span><span class="p">(</span><span class="n">Y1</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">var_type</span> <span class="o">=</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="n">reg_type</span> <span class="o">=</span> <span class="s1">&#39;ll&#39;</span><span class="p">,</span> <span class="n">bw</span> <span class="o">=</span> <span class="n">h_cv_pl</span><span class="p">)</span>
<span class="n">r_hat1</span><span class="p">,</span> <span class="n">dr_hat1</span> <span class="o">=</span> <span class="n">Kreg1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">grid</span><span class="p">)</span>
<span class="n">Kreg2</span> <span class="o">=</span> <span class="n">KernelReg</span><span class="p">(</span><span class="n">Y1</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">var_type</span> <span class="o">=</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="n">reg_type</span> <span class="o">=</span> <span class="s1">&#39;lc&#39;</span><span class="p">,</span> <span class="n">bw</span> <span class="o">=</span> <span class="n">h_cv_nw</span><span class="p">)</span>
<span class="n">r_hat2</span><span class="p">,</span> <span class="n">dr_hat2</span> <span class="o">=</span> <span class="n">Kreg2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">grid</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[165]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">g</span><span class="p">,</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y1</span><span class="p">,</span> <span class="s1">&#39;c.&#39;</span><span class="p">)</span>
<span class="n">g1</span><span class="p">,</span><span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">r_hat1</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">g2</span><span class="p">,</span><span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">r_hat2</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;yellow&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[165]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(0.0, 4.0)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../../../_images/AI_statistic_modeling_non_linear_models_nonparametric_regression_SNP_DM_DTh%C3%A9bault_76_1.png" src="../../../../../_images/AI_statistic_modeling_non_linear_models_nonparametric_regression_SNP_DM_DTh%C3%A9bault_76_1.png" />
</div>
</div>
<p>A la lecture de ce graphique, que ce soit avec les polynômes locaux ou avec Nadaraya-Watson, les estimateurs de la fonction de régression sont similaires.</p>
</section>
<section id="2.3.-(Facultatif.)-Existe-t-il-un-couple-(\alpha,\beta)-\in-\mathbb{R}^2-tel-que-le-modèle-Y_1-=-\beta-+-(X---2)^\alpha-+-\varepsilon-?">
<h2>2.3. (Facultatif.) Existe-t-il un couple <span class="math notranslate nohighlight">\((\alpha,\beta) \in \mathbb{R}^2\)</span> tel que le modèle <span class="math notranslate nohighlight">\(Y_1 = \beta + (X - 2)^\alpha + \varepsilon\)</span> ?<a class="headerlink" href="#2.3.-(Facultatif.)-Existe-t-il-un-couple-(\alpha,\beta)-\in-\mathbb{R}^2-tel-que-le-modèle-Y_1-=-\beta-+-(X---2)^\alpha-+-\varepsilon-?" title="Permalink to this heading"></a></h2>
<p>On considère uniquement les valeurs de <span class="math notranslate nohighlight">\(X\)</span> comprise dans [1,3]. Soit la fonction <span class="math notranslate nohighlight">\(r_{\alpha,\beta}(x) = \beta + (x - 2)^\alpha\)</span>, pensez-vous qu’il existe un couple <span class="math notranslate nohighlight">\((\alpha,\beta) \in \mathbb{R}^2\)</span> tel que le modèle $Y_1 = r_{<span class="math">\alpha</span>,:nbsphinx-math:<cite>beta</cite>}(X) + <span class="math">\varepsilon `$ soit adapté aux données, pour une erreur :math:</span>varepsilon sim mathcal{N}(0,1)` ? Comment estimer les valeurs de <span class="math notranslate nohighlight">\((\alpha,\beta)\)</span> ?</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[166]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Data1_inf</span> <span class="o">=</span> <span class="n">Data1</span><span class="p">[</span> <span class="p">(</span><span class="n">Data1</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">Data1</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">3</span><span class="p">)]</span> <span class="c1"># on sélectionne dans Data1 les lignes où X \in [1,3]</span>
<span class="n">g</span><span class="p">,</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Data1_inf</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">],</span><span class="n">Data1_inf</span><span class="p">[</span><span class="s1">&#39;Y1&#39;</span><span class="p">],</span> <span class="s1">&#39;c.&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="p">(</span><span class="n">grid</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="mi">9</span> <span class="o">+</span> <span class="mf">1.5</span><span class="p">)</span> <span class="c1"># Nous avons essayé de déterminer manuellement une fonction de type r s&#39;ajustant aux données.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;1 &lt;= Xi &lt;= 3&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Yi&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">2.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[166]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&lt;matplotlib.lines.Line2D at 0x7ff589895f40&gt;]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[166]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Text(0.5, 0, &#39;1 &lt;= Xi &lt;= 3&#39;)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[166]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Text(0, 0.5, &#39;Yi&#39;)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[166]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(0.5, 2.5)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../../../_images/AI_statistic_modeling_non_linear_models_nonparametric_regression_SNP_DM_DTh%C3%A9bault_79_4.png" src="../../../../../_images/AI_statistic_modeling_non_linear_models_nonparametric_regression_SNP_DM_DTh%C3%A9bault_79_4.png" />
</div>
</div>
<p>Si <span class="math notranslate nohighlight">\(\alpha &lt; 0\)</span> la fonction n’est pas définie au point <span class="math notranslate nohighlight">\(x=2\)</span>. Nous nous plaçons donc dans le cas $:nbsphinx-math:<a href="#id4"><span class="problematic" id="id5">`</span></a>alpha <a href="#id6"><span class="problematic" id="id7">`</span></a>&gt; 0 $.</p>
<p>Il est peu probable qu’il existe un couple <span class="math notranslate nohighlight">\((\alpha,\beta)\)</span> tel que le modèle $Y_1 = r_{<span class="math">\alpha</span>,:nbsphinx-math:<cite>beta</cite>}(X) + <span class="math">\epsilon `$ soit adapté aux données. Nos tentatives graphiques donnent pour le mieux un ajustement correct sur [1,3[ mais au voisinage de 3- la fonction tend vers +\ :math:</span>infty`.</p>
<p>Pour estimer le couple <span class="math notranslate nohighlight">\((\alpha,\beta)\)</span>, peut-être que nous pourrions dans un premier temps éliminier le paramètre <span class="math notranslate nohighlight">\(\beta\)</span> en estimant la densité de la dérivée de la fonction de régression et notamment la valeur de la dérivée <span class="math notranslate nohighlight">\(r_{\alpha,\beta}^{'}(3)\)</span> au point d’abscisse 3 et ainsi déterminer un estimateur de <span class="math notranslate nohighlight">\(\alpha\)</span>.</p>
<p>Graphiquement au point d’abscisse <span class="math notranslate nohighlight">\(x=2, y = \beta = 1\)</span>.</p>
</section>
</section>
<section id="3.-Etude-de-la-densité-\mu-des-\varepsilon_i">
<h1>3. Etude de la densité <span class="math notranslate nohighlight">\(\mu\)</span> des <span class="math notranslate nohighlight">\(\varepsilon_i\)</span><a class="headerlink" href="#3.-Etude-de-la-densité-\mu-des-\varepsilon_i" title="Permalink to this heading"></a></h1>
<section id="3.1.-On-cherche-à-estimer-x-\mapsto-\mu(x)-(modèle-homoscédastique)">
<h2>3.1. On cherche à estimer <span class="math notranslate nohighlight">\(x \mapsto \mu(x)\)</span> (modèle homoscédastique)<a class="headerlink" href="#3.1.-On-cherche-à-estimer-x-\mapsto-\mu(x)-(modèle-homoscédastique)" title="Permalink to this heading"></a></h2>
<section id="3.1.1.-Quelle-est-la-distribution-approximative-de-\tilde{\xi}_i-?">
<h3>3.1.1. Quelle est la distribution approximative de <span class="math notranslate nohighlight">\(\tilde{\xi}_i\)</span> ?<a class="headerlink" href="#3.1.1.-Quelle-est-la-distribution-approximative-de-\tilde{\xi}_i-?" title="Permalink to this heading"></a></h3>
<p>Par définition <span class="math notranslate nohighlight">\(\tilde{\xi}_i = Y_i - \hat{r}_{n,h}^{(-)}(X_i), i \in J_+ = [2501,...,5000]\)</span>.</p>
<p>Rappelons que la représentation des variables <span class="math notranslate nohighlight">\((X_i,Y_i)\)</span> est donnée par : <span class="math notranslate nohighlight">\(Y_i = r(X_i) + \sigma(X_i)\xi_i\)</span></p>
<p>$:nbsphinx-math:<cite>tilde{xi}</cite><em>i = Y_i - :nbsphinx-math:`hat{r}`</em>{n,h}^{(-)}(X_i) $</p>
<p>$:nbsphinx-math:<cite>tilde{xi}</cite>_i = r(X_i) + <span class="math">\sigma`(X_i):nbsphinx-math:</span>xi`<em>i - :nbsphinx-math:`hat{r}`</em>{n,h}^{(-)}(X_i) $</p>
<p>$:nbsphinx-math:<cite>tilde{xi}</cite>_i = r(X_i) + <span class="math">\sigma</span><span class="math">\xi</span><em>i - :nbsphinx-math:`hat{r}`</em>{n,h}^{(-)}(X_i) $ (homoscédasticité dans Data1)</p>
<p><span class="math notranslate nohighlight">\(\tilde{\xi}_i = r(X_i) - \hat{r}_{n,h}^{(-)}(X_i) + \sigma\xi_i\)</span></p>
<p>$:nbsphinx-math:<cite>tilde{xi}</cite>_i <span class="math">\approx `:nbsphinx-math:</span>sigma`:nbsphinx-math:<cite>xi</cite>_i $</p>
<p>La distribution approximative des $:nbsphinx-math:<cite>tilde{xi}</cite>_i $ est la distribution des $ <span class="math">\xi</span>_i $ à un facteur près $:nbsphinx-math:<a href="#id8"><span class="problematic" id="id9">`</span></a>sigma <a href="#id10"><span class="problematic" id="id11">`</span></a>$</p>
</section>
<section id="3.1.2.-En-déduire-un-estimateur-de-x-\mapsto-\mu(x)-et-l'implémenter-graphiquement">
<h3>3.1.2. En déduire un estimateur de <span class="math notranslate nohighlight">\(x \mapsto \mu(x)\)</span> et l’implémenter graphiquement<a class="headerlink" href="#3.1.2.-En-déduire-un-estimateur-de-x-\mapsto-\mu(x)-et-l'implémenter-graphiquement" title="Permalink to this heading"></a></h3>
<p>Nous reprenons h = 0.1525 estimé à la question 2.2 et <span class="math notranslate nohighlight">\(\hat{r}_{n,h}^{(-)}\)</span> l’estimateur de r construit à l’aide de <span class="math notranslate nohighlight">\((X_i, Y_i), i \in [1,...,2500]\)</span>.</p>
<p>On va commencer par couper le jeu de données Data1 en deux échantillons de même taille.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[167]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Data1_first</span> <span class="o">=</span> <span class="n">Data1</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2500</span><span class="p">]</span> <span class="c1"># sélection des 2500 premières observations</span>

<span class="n">Data1_last</span> <span class="o">=</span> <span class="n">Data1</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">2500</span><span class="p">:</span><span class="mi">5000</span><span class="p">]</span> <span class="c1"># sélection des 2500 dernières observations</span>
</pre></div>
</div>
</div>
<p>Puis construire l’estimateur de la fonction de régression sur les données <span class="math notranslate nohighlight">\(i \in J- =\)</span> {1…2500}</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[168]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">h_cv</span> <span class="o">=</span> <span class="mf">0.1525</span> <span class="c1"># repris de la question 2.2 polynômes locaux</span>

<span class="n">grid_first</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">2500</span><span class="p">)</span>

<span class="c1"># On construit l&#39;estimateur de régression à partir des données i \in J-</span>

<span class="n">Kreg3</span> <span class="o">=</span> <span class="n">KernelReg</span><span class="p">(</span><span class="n">Data1_first</span><span class="p">[</span><span class="s1">&#39;Y1&#39;</span><span class="p">],</span> <span class="n">Data1_first</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">],</span> <span class="n">var_type</span> <span class="o">=</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="n">reg_type</span> <span class="o">=</span> <span class="s1">&#39;ll&#39;</span><span class="p">,</span> <span class="n">bw</span> <span class="o">=</span> <span class="n">h_cv</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
<p>Nous en déduisons <span class="math notranslate nohighlight">\(\tilde{\xi}_i = Y_i - \hat{r}_{n,h}^{(-)}(X_i)\)</span> cette fois-ci calculé pour $i :nbsphinx-math:<a href="#id12"><span class="problematic" id="id13">`</span></a>in <a href="#id14"><span class="problematic" id="id15">`</span></a>$ {2501,…5000}</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[169]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">r_hat3</span><span class="p">,</span> <span class="n">dr_hat3</span> <span class="o">=</span> <span class="n">Kreg3</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Data1_last</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">])</span> <span class="c1"># l&#39;estimateur de régression est appliqué aux données X  i appartenant à J+</span>

<span class="n">Eps</span> <span class="o">=</span> <span class="n">Data1_last</span><span class="p">[</span><span class="s1">&#39;Y1&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">r_hat3</span> <span class="c1"># on définit epsilon comme la différence entre Yi et r(Xi) i appartenantà J+</span>
</pre></div>
</div>
</div>
<p>Représentation graphique de l’estimateur <span class="math notranslate nohighlight">\(\tilde{\xi}_i\)</span></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[170]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Eps</span><span class="p">)</span> <span class="c1"># graphique des epsilon</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># zoom sur l&#39;intervalle des ordonnées [-2; 2]</span>
<span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">5000</span><span class="p">)</span><span class="o">*</span><span class="nb">sum</span><span class="p">(</span><span class="n">Eps</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[170]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&lt;matplotlib.lines.Line2D at 0x7ff5aa317f10&gt;]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[170]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(-0.5, 2.0)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[170]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0.004008822970013314
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../../../_images/AI_statistic_modeling_non_linear_models_nonparametric_regression_SNP_DM_DTh%C3%A9bault_94_3.png" src="../../../../../_images/AI_statistic_modeling_non_linear_models_nonparametric_regression_SNP_DM_DTh%C3%A9bault_94_3.png" />
</div>
</div>
<p>Implémentation graphique de l’estimateur de $ x <span class="math">\mapsto `:nbsphinx-math:</span>mu`(x)$</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[171]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">5000</span><span class="p">)</span>
<span class="n">kde</span> <span class="o">=</span> <span class="n">KDEUnivariate</span><span class="p">(</span><span class="n">Eps</span><span class="p">)</span> <span class="c1"># Estimateur de mu(x)</span>
<span class="n">kde</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">bw</span> <span class="o">=</span> <span class="n">h_cv</span><span class="p">)</span>
<span class="n">val</span> <span class="o">=</span> <span class="n">kde</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">grid</span><span class="p">)</span>
<span class="n">g</span><span class="p">,</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Représentation de la densité des Eps&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[171]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;statsmodels.nonparametric.kde.KDEUnivariate at 0x7ff5aa3479d0&gt;
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[171]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Text(0.5, 1.0, &#39;Représentation de la densité des Eps&#39;)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../../../_images/AI_statistic_modeling_non_linear_models_nonparametric_regression_SNP_DM_DTh%C3%A9bault_96_2.png" src="../../../../../_images/AI_statistic_modeling_non_linear_models_nonparametric_regression_SNP_DM_DTh%C3%A9bault_96_2.png" />
</div>
</div>
<p>La distribution approximative des <span class="math notranslate nohighlight">\(\tilde{\xi}_i\)</span> pourrait correspondre à une loi normale.</p>
<p>Mais les tests statistiques et le boxplot ci-dessous ne permettent pas d’affirmer que les <span class="math notranslate nohighlight">\(\tilde{\xi}_i\)</span> suivent une loi normale!</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[172]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">st</span><span class="o">.</span><span class="n">shapiro</span><span class="p">(</span><span class="n">Eps</span><span class="p">)</span>
<span class="n">st</span><span class="o">.</span><span class="n">kstest</span><span class="p">(</span><span class="n">Eps</span><span class="p">,</span> <span class="s1">&#39;norm&#39;</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[172]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
ShapiroResult(statistic=0.662390410900116, pvalue=0.0)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[172]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
KstestResult(statistic=0.3409143097859602, pvalue=7.765142577883651e-260)
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[173]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#gauss = st.norm(0,1)</span>
<span class="c1">#st.probplot(Eps,dist=gauss, plot=plt)</span>
</pre></div>
</div>
</div>
<p>Pour construire l’estimateur de <span class="math notranslate nohighlight">\(x \mapsto \mu(x)\)</span> et le représenter graphiquement nous réutilisons la fonction g_hat.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[174]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mu_hat</span> <span class="o">=</span> <span class="n">g_hat</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">Eps</span><span class="p">,</span> <span class="mf">0.1525</span><span class="p">)</span>
<span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">2500</span><span class="p">)</span><span class="o">*</span><span class="nb">sum</span><span class="p">(</span><span class="n">Eps</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span><span class="n">mu_hat</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;grid&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;mu_hat&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Représentation graphique de l estimateur de mu&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[174]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0.008017645940026628
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[174]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&lt;matplotlib.lines.Line2D at 0x7ff588aff100&gt;]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[174]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Text(0.5, 0, &#39;grid&#39;)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[174]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Text(0, 0.5, &#39;mu_hat&#39;)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[174]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(-6.0, 6.0)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[174]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Text(0.5, 1.0, &#39;Représentation graphique de l estimateur de mu&#39;)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../../../_images/AI_statistic_modeling_non_linear_models_nonparametric_regression_SNP_DM_DTh%C3%A9bault_101_6.png" src="../../../../../_images/AI_statistic_modeling_non_linear_models_nonparametric_regression_SNP_DM_DTh%C3%A9bault_101_6.png" />
</div>
</div>
</section>
<section id="3.1.3.-(Facultatif)-Pourquoi-avoir-découpé-le-jeu-de-données-selon-J+-et-J--?">
<h3>3.1.3. (Facultatif) Pourquoi avoir découpé le jeu de données selon J+ et J- ?<a class="headerlink" href="#3.1.3.-(Facultatif)-Pourquoi-avoir-découpé-le-jeu-de-données-selon-J+-et-J--?" title="Permalink to this heading"></a></h3>
<p>L’intérêt d’avoir découpé le jeu de données en deux est d’avoir pu déterminer l’estimateur de la fonction de régression sur un jeu de données qui n’est pas celui utilisé pour le calcul des $:nbsphinx-math:<cite>tilde{xi}</cite>_i$ qui utilise la fonction de régression. Cela permet donc d’éviter le surapprentissage (overfitting).</p>
</section>
<section id="3.1.4.-La-densité-x-\mapsto-\mu(x)-peut-elle-être-gaussienne-?">
<h3>3.1.4. La densité <span class="math notranslate nohighlight">\(x \mapsto \mu(x)\)</span> peut-elle être gaussienne ?<a class="headerlink" href="#3.1.4.-La-densité-x-\mapsto-\mu(x)-peut-elle-être-gaussienne-?" title="Permalink to this heading"></a></h3>
<p>Nous avons ci-dessous tenté d’ajuster une loi normale <span class="math notranslate nohighlight">\(\mathcal{N}(-0.1,\,0.27)\)</span> à l’estimateur de la densité des <span class="math notranslate nohighlight">\(\tilde{\xi}_i\)</span>. L’hypothèse de normalité est plausible.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[175]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mu_hat</span> <span class="o">=</span> <span class="n">g_hat</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">Eps</span><span class="p">,</span> <span class="mf">0.1525</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">mu_hat</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">st</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.27</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;grid&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;mu_hat&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[175]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&lt;matplotlib.lines.Line2D at 0x7ff5bbc96430&gt;]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[175]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&lt;matplotlib.lines.Line2D at 0x7ff5bbc96640&gt;]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[175]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(-6.0, 6.0)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[175]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(0.0, 1.5)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[175]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Text(0.5, 0, &#39;grid&#39;)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[175]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Text(0, 0.5, &#39;mu_hat&#39;)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../../../_images/AI_statistic_modeling_non_linear_models_nonparametric_regression_SNP_DM_DTh%C3%A9bault_105_6.png" src="../../../../../_images/AI_statistic_modeling_non_linear_models_nonparametric_regression_SNP_DM_DTh%C3%A9bault_105_6.png" />
</div>
</div>
</section>
<section id="3.1.5.-(Facultatif)-Comment-peut-on-tester-si-le-modèle-est-bien-homoscédastique-?">
<h3>3.1.5. (Facultatif) Comment peut-on tester si le modèle est bien homoscédastique ?<a class="headerlink" href="#3.1.5.-(Facultatif)-Comment-peut-on-tester-si-le-modèle-est-bien-homoscédastique-?" title="Permalink to this heading"></a></h3>
<p>Pour tester l’homoscédasticité nous avons essayer d’effectuer un test de blancheur (white test). Le permier code ci-dessous trouvé sur internet ne tourne pas. A priori, il faudrait retravailler le format des Eps plutôt que l’intégrer directement à la fonction.</p>
<p>Le second test qui lui a fonctionné décrit ci-dessous est le test de blancheur appelé test de Box.Pierce. Il teste l’hypothèse H0 qu’il n’y a pas d’autocorrélation des erreurs. Les statistiques de Box.Pierce (bp-pvalue &gt;&gt; 0.05) nous permettent d’accepter H0.</p>
<p>NB: lors de cette recherche nous aurions initialement souhaité utiliser le test de Box.Pierce avec R mais nous n’avons pas réussi à installer rpy2 qui nous aurait permis de coder du R dans le Jupyter Notebook.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[176]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#from statsmodels.stats.diagnostic import het_white</span>
<span class="c1">#from statsmodels.compat import lzip</span>

<span class="c1">#keys = [&#39;Lagrange Multiplier statistic:&#39;, &#39;LM test\&#39;s p-value:&#39;, &#39;F-statistic:&#39;, &#39;F-test\&#39;s p-value:&#39;]</span>
<span class="c1">#results = het_white(Eps, grid)</span>
<span class="c1">#lzip(keys, results)</span>

<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="n">sm</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">diagnostic</span><span class="o">.</span><span class="n">acorr_ljungbox</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">Eps</span><span class="p">,</span> <span class="n">lags</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="n">boxpierce</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">model_df</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">period</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_df</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">auto_lag</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[176]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>lb_stat</th>
      <th>lb_pvalue</th>
      <th>bp_stat</th>
      <th>bp_pvalue</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>1.035763</td>
      <td>0.308809</td>
      <td>1.034521</td>
      <td>0.309099</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.150236</td>
      <td>0.562638</td>
      <td>1.148811</td>
      <td>0.563039</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</section>
</section>
<section id="3.1.-On-cherche-à-estimer-x-\mapsto-\mu(x)-(cas-du-modèle-hétéroscédastique)">
<h2>3.1. On cherche à estimer <span class="math notranslate nohighlight">\(x \mapsto \mu(x)\)</span> (cas du modèle hétéroscédastique)<a class="headerlink" href="#3.1.-On-cherche-à-estimer-x-\mapsto-\mu(x)-(cas-du-modèle-hétéroscédastique)" title="Permalink to this heading"></a></h2>
<p>On cherche à estimer <span class="math notranslate nohighlight">\(x \mapsto \mu(x)\)</span> et <span class="math notranslate nohighlight">\(x \mapsto \sigma(x)\)</span>. Pour cela, on coupe à nouveau l’échantillon en deux et on considère à nouveau <span class="math notranslate nohighlight">\(\tilde{\xi}_i\)</span>.</p>
<p>On coupe le jeu de données Data2 en deux échantillons et on considère à nouveau <span class="math notranslate nohighlight">\(\tilde{\xi}_i\)</span></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[177]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Data2_first</span> <span class="o">=</span> <span class="n">Data2</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2500</span><span class="p">]</span> <span class="c1"># sélection des 2500 premières observations</span>

<span class="n">Data2_last</span> <span class="o">=</span> <span class="n">Data2</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">2500</span><span class="p">:</span><span class="mi">5000</span><span class="p">]</span> <span class="c1"># sélection des 2500 dernières observations</span>
</pre></div>
</div>
</div>
<section id="3.2.1.-Justifier-qu'en-régressant-\tilde{\xi}_i^2-sur-Xi-on-obtient-un-estimateur-de-x-\mapsto-\sigma^2(x).">
<h3>3.2.1. Justifier qu’en régressant <span class="math notranslate nohighlight">\(\tilde{\xi}_i^2\)</span> sur Xi on obtient un estimateur de <span class="math notranslate nohighlight">\(x \mapsto \sigma^2(x)\)</span>.<a class="headerlink" href="#3.2.1.-Justifier-qu'en-régressant-\tilde{\xi}_i^2-sur-Xi-on-obtient-un-estimateur-de-x-\mapsto-\sigma^2(x)." title="Permalink to this heading"></a></h3>
<p>L’implémenter et le visualiser graphiquement. En comparant avec le jeu de données (Figure 1 à droite), retrouve-t-on un résultat attendu ?</p>
<p>La régression de <span class="math notranslate nohighlight">\(\tilde{\xi}_i^2\)</span> selon <span class="math notranslate nohighlight">\(X_i\)</span> nous fournit bien un estimateur de la fonction <span class="math notranslate nohighlight">\(\sigma^2\)</span>, pour preuve:</p>
<p>Pour rappel, on a défini par <span class="math notranslate nohighlight">\(\tilde{\xi}_i = Y_i - \hat{r}_{n,h}^{(-)}(X_i)\)</span></p>
<p>$:nbsphinx-math:<cite>mathbb{E}`[:nbsphinx-math:</cite>tilde{xi}`_i^2 :nbsphinx-math:<a href="#id16"><span class="problematic" id="id17">`</span></a>mid <a href="#id18"><span class="problematic" id="id19">`</span></a>X_i] $</p>
<p>$= <span class="math">\mathbb{E}`[(Y_i - :nbsphinx-math:</span>hat{r}`(X_i))^2 :nbsphinx-math:<a href="#id20"><span class="problematic" id="id21">`</span></a>mid <a href="#id22"><span class="problematic" id="id23">`</span></a>X_i] $</p>
<p>$:nbsphinx-math:<cite>approx `:nbsphinx-math:</cite>mathbb{E}`[(Y_i - r(X_i))^2 :nbsphinx-math:<a href="#id24"><span class="problematic" id="id25">`</span></a>mid <a href="#id26"><span class="problematic" id="id27">`</span></a>X_i] $</p>
<p>$= <span class="math">\mathbb{E}`[:nbsphinx-math:</span>sigma`^2(X_i):nbsphinx-math:<cite>xi</cite>_i^2 :nbsphinx-math:<a href="#id28"><span class="problematic" id="id29">`</span></a>mid <a href="#id30"><span class="problematic" id="id31">`</span></a>X_i] $</p>
<p>$= <span class="math">\sigma`^2(X_i):nbsphinx-math:</span>mathbb{E}`[<span class="math">\xi</span>_i^2 :nbsphinx-math:<a href="#id32"><span class="problematic" id="id33">`</span></a>mid <a href="#id34"><span class="problematic" id="id35">`</span></a>X_i] $</p>
<p>$= <span class="math">\sigma`^2(X_i):nbsphinx-math:</span>mathbb{E}`[<span class="math">\xi</span>_i^2] $</p>
<p><span class="math notranslate nohighlight">\(= \sigma^2(X_i)\)</span></p>
<p>Pour implémenter l’estimateur de <span class="math notranslate nohighlight">\(\sigma^2\)</span> à partir des données Data2, comme précédemment nous devons déterminer la taille de la fenêtre de lissage que nous allons utiliser.</p>
<p>Comme pour la partie 3.1 nous allons déterminer la fonction de régression en régressant les <span class="math notranslate nohighlight">\(Y_i\)</span> sur <span class="math notranslate nohighlight">\(X_i\)</span> en utilisant la première partie du jeu de données Data2. La seconde partie du jeu de données Data2 sera utilisée pour construire l’estimateur et ainsi éviter le surapprentissage.</p>
<p>Nous allons réestimer h par la méthode des polynômes locaux.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[178]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>

<span class="n">Kreg4</span> <span class="o">=</span> <span class="n">KernelReg</span><span class="p">(</span><span class="n">Data2_first</span><span class="p">[</span><span class="s1">&#39;Y2&#39;</span><span class="p">],</span> <span class="n">Data2_first</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">],</span> <span class="n">var_type</span> <span class="o">=</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="n">reg_type</span> <span class="o">=</span> <span class="s1">&#39;ll&#39;</span><span class="p">,</span> <span class="n">bw</span> <span class="o">=</span> <span class="s1">&#39;cv_ls&#39;</span><span class="p">)</span>
<span class="n">h_cv_4</span> <span class="o">=</span> <span class="n">Kreg4</span><span class="o">.</span><span class="n">bw</span>

<span class="n">h_cv_4</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[178]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([0.45751393])
</pre></div></div>
</div>
<p>Maintenant que h est estimé, nous régressons <span class="math notranslate nohighlight">\(Y_i\)</span> sur <span class="math notranslate nohighlight">\(X_i\)</span> pour $i <span class="math">\in `${1,...,2500} pour déterminer :math:</span>hat{r}_{n,h}`</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[179]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">h_cv_4</span> <span class="o">=</span> <span class="mf">0.4575</span>
<span class="n">Kreg5</span> <span class="o">=</span> <span class="n">KernelReg</span><span class="p">(</span><span class="n">Data2_first</span><span class="p">[</span><span class="s1">&#39;Y2&#39;</span><span class="p">],</span> <span class="n">Data2_first</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">],</span> <span class="n">var_type</span> <span class="o">=</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="n">reg_type</span> <span class="o">=</span> <span class="s1">&#39;ll&#39;</span><span class="p">,</span> <span class="n">bw</span> <span class="o">=</span> <span class="n">h_cv_4</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">r_hat5</span><span class="p">,</span> <span class="n">dr_hat5</span> <span class="o">=</span> <span class="n">Kreg5</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Data2_last</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<p>Nous pouvons désormais implémenter l’estimateur de <span class="math notranslate nohighlight">\(x \mapsto \sigma(x)^2\)</span> et le visualiser graphiquement.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[180]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Eps2</span> <span class="o">=</span> <span class="p">(</span><span class="n">Data2_last</span><span class="p">[</span><span class="s1">&#39;Y2&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">r_hat5</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
<span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">4999</span><span class="p">)</span><span class="o">*</span><span class="nb">sum</span><span class="p">(</span><span class="n">Eps2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Eps2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[180]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
2.0095274740242237
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[180]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&lt;matplotlib.lines.Line2D at 0x7ff5bbd71b50&gt;]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../../../_images/AI_statistic_modeling_non_linear_models_nonparametric_regression_SNP_DM_DTh%C3%A9bault_122_2.png" src="../../../../../_images/AI_statistic_modeling_non_linear_models_nonparametric_regression_SNP_DM_DTh%C3%A9bault_122_2.png" />
</div>
</div>
<p>En comparant avec le jeu de données, retrouve-t-on le résultat attendu ?</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[181]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Data2</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[181]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>X</th>
      <th>Y2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>5000.000000</td>
      <td>5000.000000</td>
      <td>5000.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>2500.500000</td>
      <td>3.527486</td>
      <td>1.226723</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1443.520003</td>
      <td>1.839532</td>
      <td>2.075400</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>-7.603334</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>1250.750000</td>
      <td>1.617688</td>
      <td>0.233537</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>2500.500000</td>
      <td>3.576746</td>
      <td>1.046899</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>3750.250000</td>
      <td>5.418334</td>
      <td>2.250319</td>
    </tr>
    <tr>
      <th>max</th>
      <td>5000.000000</td>
      <td>6.000000</td>
      <td>10.562283</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</section>
<section id="3.2.2.-La-densité-x-\mapsto-\mu(x)-peut-elle-être-gaussienne-?">
<h3>3.2.2. La densité <span class="math notranslate nohighlight">\(x \mapsto \mu(x)\)</span> peut-elle être gaussienne ?<a class="headerlink" href="#3.2.2.-La-densité-x-\mapsto-\mu(x)-peut-elle-être-gaussienne-?" title="Permalink to this heading"></a></h3>
<p>Proposer un protocole pour le vérifier empiriquement et l’implémenter. On pourra penser à renormaliser <span class="math notranslate nohighlight">\(\tilde{\xi}_i\)</span> par la fonction estimée à la question précédente et s’aider des questions de la Section 3.1.</p>
<p>Cette question nous a posé des difficultés. Nous proposons ici une solution mais l’issue de notre protocole était très certainement prévisible en vertue du théorême centrale limite. Nous le décrivons quand même:</p>
<p>Si <span class="math notranslate nohighlight">\(x \mapsto \mu(x)\)</span> est gaussienne alors les $ <span class="math">\tilde{\xi}</span>_i <span class="math">\sim `:nbsphinx-math:</span>mathcal{N}`(<span class="math">\mu</span>,:nbsphinx-math:<cite>sigma</cite>)$. On en déduit alors que $ <span class="math">\frac{\tilde{\xi}_i- \mu}{\sigma^2}</span> <span class="math">\sim `:nbsphinx-math:</span>mathcal{N}`(0,1)$. Nous proposons de vérifier cette dernière assertion par un test de blancheur.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[182]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Eps</span> <span class="o">=</span> <span class="n">Data2_last</span><span class="p">[</span><span class="s1">&#39;Y2&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">r_hat5</span>
<span class="n">mu_hat</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">n</span><span class="p">)</span><span class="o">*</span><span class="nb">sum</span><span class="p">(</span><span class="n">Eps</span><span class="p">)</span>
<span class="n">sigma_hat</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">*</span><span class="nb">sum</span><span class="p">(</span><span class="n">Eps2</span><span class="p">)</span>
<span class="n">Eps_norm</span> <span class="o">=</span> <span class="p">(</span><span class="n">Eps</span> <span class="o">-</span> <span class="n">mu_hat</span><span class="p">)</span><span class="o">/</span><span class="n">sigma_hat</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Eps_norm</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="n">sm</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">diagnostic</span><span class="o">.</span><span class="n">acorr_ljungbox</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">Eps_norm</span><span class="p">,</span> <span class="n">lags</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="n">boxpierce</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">model_df</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">period</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_df</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">auto_lag</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[182]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&lt;matplotlib.lines.Line2D at 0x7ff5a9daba60&gt;]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[182]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>lb_stat</th>
      <th>lb_pvalue</th>
      <th>bp_stat</th>
      <th>bp_pvalue</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0.021875</td>
      <td>0.882421</td>
      <td>0.021848</td>
      <td>0.882491</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2.634154</td>
      <td>0.267917</td>
      <td>2.629951</td>
      <td>0.268481</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../../../_images/AI_statistic_modeling_non_linear_models_nonparametric_regression_SNP_DM_DTh%C3%A9bault_127_2.png" src="../../../../../_images/AI_statistic_modeling_non_linear_models_nonparametric_regression_SNP_DM_DTh%C3%A9bault_127_2.png" />
</div>
</div>
<p>Nous avons bien la représentation d’un bruit blanc ce que confirme le test de Box.Pierce. La densité <span class="math notranslate nohighlight">\(x -&gt; \mapsto \mu(x)\)</span> peut-être gaussienne.</p>
<p>Conclusion:</p>
<p>Ce devoir nous a permis de manipuler les fonctions d’estimation de densité dans le cadre non paramétrique, d’appliquer les algorithmes de validation croisée de Nadaray-Watson pour déterminer l’estimateur d’un hyperparamètre mais aussi de faire de la régression linéaire non paramétrique. Bien souvent, l’habitude nous a conduit à nous rapprocher de notions utilisées en statistiques paramétriques tels que les tests de blancheur pour répondre aux questions.</p>
<p>Dans ce devoir, un des points qui m’interroge concerne la représentation graphique de l’estimateur <span class="math notranslate nohighlight">\(\tilde{\xi}_i\)</span>. En effet sa variance semblait tronquée pour les valeurs négatives. Je serai curieux de connaître l’algorithme ayant permis de construire ce jeu de données.</p>
<p>Outre la discipline statistique enseignée lors de ce cours, ce devoir nous a permis de nous initier à la programmation avec Python. Cette relatie inexpérience ne nous a pas permis de finaliser l’installation de rpy2. Dommage car il aurait été intéressant de comparer les sorties fournies par les programmes R avec ceux de Python mais l’installation de rpy2 a buggé. Nous retenterons cet essai lors d’un prochain devoir.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, David TBO.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>