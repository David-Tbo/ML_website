

<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Clustering: t-SNE &mdash; My AI website 0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/nbsphinx-code-cells.css?v=2aa19091" />

  
      <script src="../../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js?v=e031e9a9"></script>
      <script src="../../../../_static/doctools.js?v=888ff710"></script>
      <script src="../../../../_static/sphinx_highlight.js?v=4825356b"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="Clustering: Sammon Mapping" href="ML_labDauphine_unsupervised_7_Sammon_Mapping.html" />
    <link rel="prev" title="Clustering: ISOMAP" href="ML_labDauphine_unsupervised_5_ISOMAP.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../index.html" class="icon icon-home">
            My AI website
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../probabilities/index.html">Probability Theory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../statistic/index.html">Statistical Methods</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../index.html">Machine Learning</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../../index.html#notebooks">Notebooks</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="../index.html">Unsupervised learning</a><ul class="current">
<li class="toctree-l4 current"><a class="reference internal" href="../index.html#notebooks">Notebooks</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">My AI website</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Machine Learning</a></li>
          <li class="breadcrumb-item"><a href="../index.html">Unsupervised learning</a></li>
      <li class="breadcrumb-item active">Clustering: t-SNE</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../../_sources/AI/machine_learning/unsupervised_learning/notebooks/ML_labDauphine_unsupervised_6_tSNE.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="Clustering:-t-SNE">
<h1>Clustering: t-SNE<a class="headerlink" href="#Clustering:-t-SNE" title="Permalink to this heading"></a></h1>
<blockquote>
<div><p><strong>t-SNE (t-distributed Stochastic Neighbor Embedding) is a nonlinear dimensionality reduction algorithm designed to preserve local neighborhood relationships. It transforms distances between points into similarity probabilities, both in the original space and the projected space, and seeks to minimize the KL divergence between the two.</strong></p>
</div></blockquote>
<p>The dataset:</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Point</p></th>
<th class="head"><p>Coordonnées</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>A</p></td>
<td><p>(1, 1)</p></td>
</tr>
<tr class="row-odd"><td><p>B</p></td>
<td><p>(2, 1)</p></td>
</tr>
<tr class="row-even"><td><p>C</p></td>
<td><p>(4, 3)</p></td>
</tr>
<tr class="row-odd"><td><p>D</p></td>
<td><p>(5, 4)</p></td>
</tr>
<tr class="row-even"><td><p>E</p></td>
<td><p>(3, 4)</p></td>
</tr>
</tbody>
</table>
<ul class="simple">
<li><p><strong>Step-0: Matrix of euclidean distances</strong></p></li>
</ul>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>A</p></th>
<th class="head"><p>B</p></th>
<th class="head"><p>C</p></th>
<th class="head"><p>D</p></th>
<th class="head"><p>E</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>A</p></td>
<td><p>0.0</p></td>
<td><p>1.0</p></td>
<td><p>3.6</p></td>
<td><p>5.0</p></td>
<td><p>3.6</p></td>
</tr>
<tr class="row-odd"><td><p>B</p></td>
<td><p>1.0</p></td>
<td><p>0.0</p></td>
<td><p>2.8</p></td>
<td><p>4.2</p></td>
<td><p>3.2</p></td>
</tr>
<tr class="row-even"><td><p>C</p></td>
<td><p>3.6</p></td>
<td><p>2.8</p></td>
<td><p>0.0</p></td>
<td><p>1.4</p></td>
<td><p>1.4</p></td>
</tr>
<tr class="row-odd"><td><p>D</p></td>
<td><p>5.0</p></td>
<td><p>4.2</p></td>
<td><p>1.4</p></td>
<td><p>0.0</p></td>
<td><p>2.0</p></td>
</tr>
<tr class="row-even"><td><p>E</p></td>
<td><p>3.6</p></td>
<td><p>3.2</p></td>
<td><p>1.4</p></td>
<td><p>2.0</p></td>
<td><p>0.0</p></td>
</tr>
</tbody>
</table>
<ul class="simple">
<li><p><strong>Step-1: Compute the similarities in the space of origin</strong></p></li>
</ul>
<p><strong>1.1 Compute the conditional probabilities :math:`p_{j|i}`.</strong></p>
<div class="line-block">
<div class="line">In t-SNE, each point <span class="math notranslate nohighlight">\(x_i\)</span> defines a conditional probability distribution over all other points <span class="math notranslate nohighlight">\(x_j\)</span>, which reflects how likely <span class="math notranslate nohighlight">\(x_j\)</span> is to be a neighbor of <span class="math notranslate nohighlight">\(x_i\)</span>.</div>
<div class="line">This is computed using a Gaussian distribution centered at <span class="math notranslate nohighlight">\(x_i\)</span>:</div>
</div>
<div class="math notranslate nohighlight">
\[p_{j|i} = \dfrac{exp(-||x_i - x_j||^2 / 2\sigma_i^2)}{\sum_{k \neq i}exp(-||x_i - x_k||^2 / 2\sigma_i^2)}\]</div>
<ul>
<li><p><span class="math notranslate nohighlight">\(\sigma_i\)</span> is the bandwith of the Gaussian centered at <span class="math notranslate nohighlight">\(x_i\)</span>.</p></li>
<li><p>It is usually determined automatically via binary search to match a predefinied <strong>perplexity</strong> (which controls the effective number of neighbors, typically 5-50).</p></li>
<li><p>The perplexity corresponds to the entropy <span class="math notranslate nohighlight">\(H(p_i)\)</span> of the distribution:</p>
<div class="math notranslate nohighlight">
\[\text{Perplexity}(p_i) = 2^{H(p_i)} \Rightarrow H(p_i) = log_2(\text{Perplexity})\]</div>
<p>In this example, we assume perplexity = 2, so:</p>
<div class="math notranslate nohighlight">
\[H_(p_i) \approx \log_2(2) = 1\]</div>
</li>
</ul>
<p>For simplification, we assume that <span class="math notranslate nohighlight">\(\sigma_i = 1\)</span> for all points (i.e., we skip the binary search and fix the bandwidth).</p>
<p>Example with the conditional probabilities for the point <span class="math notranslate nohighlight">\(A\)</span>:</p>
<p>Distance from point <span class="math notranslate nohighlight">\(x_i = A\)</span> to others: <span class="math notranslate nohighlight">\([0.0, 1.0, 3.6, 5.0, 3.6]\)</span></p>
<p>We ignore the distance to itself <span class="math notranslate nohighlight">\((0.0)\)</span>, and compute unnormalized similarities <span class="math notranslate nohighlight">\(p_{j|A} = exp(-\dfrac{d^2}{2})\)</span>:</p>
<p>B: <span class="math notranslate nohighlight">\(exp(-\dfrac{1^2}{2}) = exp(-0.5) \approx 0.6065\)</span></p>
<p>C: <span class="math notranslate nohighlight">\(exp(-\dfrac{3.6^2}{2}) = exp(-6.48) \approx 0.0015\)</span></p>
<p>D: <span class="math notranslate nohighlight">\(exp(-\dfrac{5.0^2}{2}) = exp(-12.5) \approx 3.726e-6\)</span></p>
<p>E: <span class="math notranslate nohighlight">\(exp(-\dfrac{3.6^2}{2}) = exp(-6.48) \approx 0.0015\)</span></p>
<p>Now normalize:</p>
<p><span class="math notranslate nohighlight">\(\sum_{j \neq A}exp(-\dfrac{||x_A - x_j||^2}{2}) = 0.6065 + 0.0015 + 3.7e-6 + 0.0015 \approx 0.6095\)</span></p>
<div class="math notranslate nohighlight">
\[\Rightarrow p_{B|A} \approx \dfrac{0.6065}{0.6095} \approx 0.995\]</div>
<p>This means that point <span class="math notranslate nohighlight">\(A\)</span> considers point <span class="math notranslate nohighlight">\(B\)</span> to be a very likely neighbor, while points <span class="math notranslate nohighlight">\(C, D\)</span>, and <span class="math notranslate nohighlight">\(E\)</span> are effectively ignored.</p>
<p>The conditional probability <span class="math notranslate nohighlight">\(p_{j|i}\)</span> captures how similar or close point <span class="math notranslate nohighlight">\(j\)</span> is to point <span class="math notranslate nohighlight">\(i\)</span>.</p>
<p><strong>1.2 Symetrisation.</strong></p>
<div class="line-block">
<div class="line">The values of the conditional probabilities are asymmetric meaning <span class="math notranslate nohighlight">\(p_{j|i} \neq p_{i|j}\)</span>.</div>
<div class="line">To obtain a joint probability distribution over pairs of points, t-SNE symmetrizes them as follows:</div>
</div>
<div class="math notranslate nohighlight">
\[p_{ij} = \dfrac{p_{j|i} + p_{i|j}}{2n}\]</div>
<p>Here, <span class="math notranslate nohighlight">\(n\)</span> is the number of data points. This results in a symmetric matrix of pairwise similarities in the original high we obtain a symetric matrix of similarity in the original high-dimensional space.</p>
<ul class="simple">
<li><p><strong>Step-2: Compute the similarities in the ‘espace bas’ (2D)</strong></p></li>
</ul>
<p>We now map the data points into a low-dimensional space—typically 2D—by assigning each point a randomly initialized position $y_i. Then, we compute a new similarity measure <span class="math notranslate nohighlight">\(q_{ij}\)</span> between <span class="math notranslate nohighlight">\(y_i\)</span> and <span class="math notranslate nohighlight">\(y_j\)</span> using a Student’s t-Distribution with one degree of freedom (also known as a Cauchy distribution):</p>
<div class="math notranslate nohighlight">
\[q_{ij} = \dfrac{(1 + ||y_i - y_j||^2)^{-1}}{\sum_{k \neq l}(1 + ||y_k - y_l||^2)^{-1}}\]</div>
<p>This heavy-tailed distribution helps to strongly repel dissimilar points, improving the separation in the 2D projection compared to a Gaussian.</p>
<ul class="simple">
<li><p><strong>Step-3: Minimization de la divergence KL</strong></p></li>
</ul>
<p>The goal of t-SNE is to make the low-dimensional distribution <span class="math notranslate nohighlight">\(Q = {q_{ij}}\)</span> resemble the high-dimensional distribution <span class="math notranslate nohighlight">\(P={p_{ij}}\)</span>. To achieve this, we miinimize the Kullback-Leibler (KL) divergence between the two distributions:</p>
<div class="math notranslate nohighlight">
\[KL(P||Q) = \sum_{i \neq j}p{ij}log \dfrac{p_{ij}}{q_{ij}}\]</div>
<p>This loss function is minimized using gradient descent. The gradient of the cost function with respect to a point <span class="math notranslate nohighlight">\(y_i\)</span> is given by:</p>
<div class="math notranslate nohighlight">
\[\dfrac{dC}{dy_i} = 4 \sum_j(p_{ij} - q_{ij})(y_i - y_j)(1 + ||y_i - y_j||^2)^{-1}\]</div>
<p>This update moves the low-dimensional points <span class="math notranslate nohighlight">\(y_i\)</span> in a way that:</p>
<ul class="simple">
<li><p>Pulls similar points closer (when <span class="math notranslate nohighlight">\(p{ij} &gt; q{ij}\)</span>),</p></li>
<li><p>Pushes dissimilar points apart (when <span class="math notranslate nohighlight">\(p{ij} &lt; q{ij}\)</span>).</p></li>
</ul>
<p>The positions of the low-dimensional points <span class="math notranslate nohighlight">\(y_i\)</span> are updated iteratively until convergence.</p>
<p>📌 Conclusion: Why t-SNE Preserves Local Structure.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Property</p></th>
<th class="head"><p>Explanation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Gaussian distribution</p></td>
<td><p>Models neighborhoods in the original high-dimensional space</p></td>
</tr>
<tr class="row-odd"><td><p>Student’s t-distribution</p></td>
<td><p>Strongly separates dissimilar points in the low-dimensional space</p></td>
</tr>
<tr class="row-even"><td><p>KL divergence as cost</p></td>
<td><p>Ensures an accurate reconstruction of <strong>local relationships</strong></p></td>
</tr>
<tr class="row-odd"><td><p>Suitable for visualization</p></td>
<td><p>t-SNE produces intuitive and readable visualizations, even for non-experts</p></td>
</tr>
</tbody>
</table>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.manifold</span> <span class="kn">import</span> <span class="n">TSNE</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">points</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;A&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="s1">&#39;B&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
    <span class="s1">&#39;D&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
    <span class="s1">&#39;E&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="p">}</span>
<span class="n">labels</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">points</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">points</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">])</span>

<span class="n">tsne</span> <span class="o">=</span> <span class="n">TSNE</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">perplexity</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;random&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X_emb</span> <span class="o">=</span> <span class="n">tsne</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">labels</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X_emb</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">y</span> <span class="o">+</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Projection t-SNE (perplexité = 2)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../../_images/AI_machine_learning_unsupervised_learning_notebooks_ML_labDauphine_unsupervised_6_tSNE_3_0.png" src="../../../../_images/AI_machine_learning_unsupervised_learning_notebooks_ML_labDauphine_unsupervised_6_tSNE_3_0.png" />
</div>
</div>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="ML_labDauphine_unsupervised_5_ISOMAP.html" class="btn btn-neutral float-left" title="Clustering: ISOMAP" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="ML_labDauphine_unsupervised_7_Sammon_Mapping.html" class="btn btn-neutral float-right" title="Clustering: Sammon Mapping" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, David TBO.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>